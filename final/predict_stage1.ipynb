{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "import torch.optim as optim\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the gradient boosting regression model with PyTorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, outputs, labels):\n",
    "        # Define your custom loss function here\n",
    "        # This is a simple example, replace it with your own function\n",
    "        custom_loss = 3*(torch.abs(labels - outputs))*(torch.abs(labels - 1/3) + torch.abs(labels -2/3))\n",
    "        return custom_loss\n",
    "    \n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    input_size = 8\n",
    "    hidden_size = trial.suggest_int('hidden_size', 3, 10000, log=True)  # Single hidden size for all layers\n",
    "    output_size = 1\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e1, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)\n",
    "\n",
    "    # Instantiate the model with sampled hyperparameters\n",
    "    model = Net(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = CustomLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(100):\n",
    "        training_loss = 0.0\n",
    "        eval_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.reshape(-1)\n",
    "            loss = criterion(outputs, labels).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        # Iterate over the DataLoader for test data\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                outputs = model(inputs).reshape(-1)\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                eval_loss += loss\n",
    "\n",
    "        # Optuna logs the running loss for each epoch\n",
    "        trial.report(eval_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Return the running loss as the objective value to minimize\n",
    "    return eval_loss\n",
    "\n",
    "\n",
    "class station_model():\n",
    "    def __init__(self, station):\n",
    "        self.station = station\n",
    "\n",
    "    def get_data_loader(self):\n",
    "        df = pd.read_parquet(f'parquets/{self.station}.parquet')\n",
    "        TOT = df['tot'].iloc[0]\n",
    "        df['sbi'] = df['sbi']/TOT\n",
    "        df['time'] = df['time']/1440\n",
    "\n",
    "        # x is dataset without 'sbi', y is 'sbi'\n",
    "        X = df.drop(['tot', 'sbi','bemp' ,'act', 'tot', 'station'], axis=1)\n",
    "        y = df['sbi']\n",
    "\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "\n",
    "        X = torch.from_numpy(X)\n",
    "        y = torch.from_numpy(y)\n",
    "        dataset = TensorDataset(X, y)\n",
    "\n",
    "        # get train, test loader\n",
    "        self.all_data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # split train, test\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        # get train, test loader\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "        print(f'get data loader for {self.station}')\n",
    "\n",
    "    def objective(self,trial):\n",
    "        # Sample hyperparameters\n",
    "        input_size = 8\n",
    "        hidden_size = trial.suggest_int('hidden_size', 3, 5000, log=True)  # Single hidden size for all layers\n",
    "        output_size = 1\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e1, log=True)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "\n",
    "        # Instantiate the model with sampled hyperparameters\n",
    "        model = Net(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = CustomLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(100):\n",
    "            training_loss = 0.0\n",
    "            eval_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.reshape(-1)\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.item()\n",
    "\n",
    "            model.eval()\n",
    "            # Iterate over the DataLoader for test data\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(self.test_loader):\n",
    "                    inputs, labels = data\n",
    "                    inputs = inputs.float()\n",
    "                    labels = labels.float()\n",
    "                    outputs = model(inputs).reshape(-1)\n",
    "                    loss = criterion(outputs, labels).sum()\n",
    "                    eval_loss += loss\n",
    "\n",
    "            # Optuna logs the running loss for each epoch\n",
    "            trial.report(eval_loss, epoch)\n",
    "            # Handle pruning based on the intermediate value\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "        # Return the running loss as the objective value to minimize\n",
    "        return eval_loss      \n",
    "\n",
    "\n",
    "    def get_best_param(self):\n",
    "        # Create an Optuna Study\n",
    "        study = optuna.create_study(direction='minimize', storage='sqlite:///db.sqlite3', study_name=f'{self.station}', load_if_exists=True)\n",
    "\n",
    "        # Run the optimization process\n",
    "        study.optimize(self.objective, n_trials=10)\n",
    "\n",
    "        print(f'{self.station} eval_loss: {study.best_trial.value}')\n",
    "\n",
    "        # Access the best hyperparameters\n",
    "        best_params = study.best_trial.params\n",
    "\n",
    "        self.best_params = best_params\n",
    "\n",
    "        print(self.station,' Best hyperparameters:', best_params)\n",
    "\n",
    "    def train(self):\n",
    "        # Instantiate the final model with the best hyperparameters\n",
    "        final_model = Net(8, self.best_params['hidden_size'], 1, self.best_params['dropout_rate'])\n",
    "\n",
    "        # ... rest of your training code for the final model\n",
    "        criterion = CustomLoss()\n",
    "        optimizer = optim.Adam(final_model.parameters(), lr=self.best_params['learning_rate'])\n",
    "\n",
    "        # train with whole dataset\n",
    "        running_loss = 0.0\n",
    "        for epoch in range(10):\n",
    "            for i, data in enumerate(self.all_data_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = final_model(inputs)\n",
    "                outputs = outputs.squeeze()\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()/128\n",
    "            print(f'epoch: {epoch+1}, loss: {running_loss/self.all_data_loader.__len__()}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "        final_model.eval()\n",
    "        # save model\n",
    "        torch.save(final_model.state_dict(), f'models/model_{self.station}.pt')\n",
    "\n",
    "def get_one_hot_weekday(date_str):\n",
    "    # Convert the date string to a datetime object\n",
    "    date = datetime.datetime.strptime(date_str, '%Y%m%d')\n",
    "    \n",
    "    # Get the weekday (Monday is 0, Sunday is 6)\n",
    "    weekday = date.weekday()\n",
    "    \n",
    "    # Create a one-hot encoded list for the weekday\n",
    "    one_hot_weekday = [1 if i == weekday else 0 for i in range(7)]\n",
    "    \n",
    "    return one_hot_weekday\n",
    "\n",
    "def time_to_minute(time_str):\n",
    "    hours, minutes = map(int, time_str.split(':'))\n",
    "    total_minutes = hours * 60 + minutes\n",
    "    return total_minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission data\n",
    "\n",
    "df = pd.read_csv('html.2023.final.data/sample_submission_stage1.csv')\n",
    "# ['time', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']\n",
    "submission = pd.DataFrame(columns=['id','time', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'])\n",
    "stationTOT = {}\n",
    "rows = []\n",
    "for x in df['id']:\n",
    "    TOT = 1\n",
    "    date = x[:8]\n",
    "    station = x[9:18]\n",
    "    time = x[19:]\n",
    "    one_hot_weekday = get_one_hot_weekday(date)\n",
    "    time = time_to_minute(time)/1440\n",
    "    row = {'id': x,'time':time, 'mon':one_hot_weekday[0], 'tue':one_hot_weekday[1], 'wed':one_hot_weekday[2], 'thu':one_hot_weekday[3], 'fri':one_hot_weekday[4], 'sat':one_hot_weekday[5], 'sun':one_hot_weekday[6], f'{station}':1}\n",
    "    rows.append(row)\n",
    "\n",
    "submission = pd.DataFrame(rows)\n",
    "submission = submission.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>mon</th>\n",
       "      <th>tue</th>\n",
       "      <th>wed</th>\n",
       "      <th>thu</th>\n",
       "      <th>fri</th>\n",
       "      <th>sat</th>\n",
       "      <th>sun</th>\n",
       "      <th>500101001</th>\n",
       "      <th>...</th>\n",
       "      <th>500101030</th>\n",
       "      <th>500101031</th>\n",
       "      <th>500101032</th>\n",
       "      <th>500101033</th>\n",
       "      <th>500101034</th>\n",
       "      <th>500101035</th>\n",
       "      <th>500101036</th>\n",
       "      <th>500101037</th>\n",
       "      <th>500101038</th>\n",
       "      <th>500101039</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20231204_500101001_00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20231204_500101001_00:20</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20231204_500101001_00:40</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20231204_500101001_01:00</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20231204_500101001_01:20</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88699</th>\n",
       "      <td>20231024_500119091_22:20</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88700</th>\n",
       "      <td>20231024_500119091_22:40</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88701</th>\n",
       "      <td>20231024_500119091_23:00</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88702</th>\n",
       "      <td>20231024_500119091_23:20</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88703</th>\n",
       "      <td>20231024_500119091_23:40</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88704 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id      time  mon  tue  wed  thu  fri  sat  sun  \\\n",
       "0      20231204_500101001_00:00  0.000000    1    0    0    0    0    0    0   \n",
       "1      20231204_500101001_00:20  0.013889    1    0    0    0    0    0    0   \n",
       "2      20231204_500101001_00:40  0.027778    1    0    0    0    0    0    0   \n",
       "3      20231204_500101001_01:00  0.041667    1    0    0    0    0    0    0   \n",
       "4      20231204_500101001_01:20  0.055556    1    0    0    0    0    0    0   \n",
       "...                         ...       ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "88699  20231024_500119091_22:20  0.930556    0    1    0    0    0    0    0   \n",
       "88700  20231024_500119091_22:40  0.944444    0    1    0    0    0    0    0   \n",
       "88701  20231024_500119091_23:00  0.958333    0    1    0    0    0    0    0   \n",
       "88702  20231024_500119091_23:20  0.972222    0    1    0    0    0    0    0   \n",
       "88703  20231024_500119091_23:40  0.986111    0    1    0    0    0    0    0   \n",
       "\n",
       "       500101001  ...  500101030  500101031  500101032  500101033  500101034  \\\n",
       "0            1.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "1            1.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "2            1.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "3            1.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "4            1.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "...          ...  ...        ...        ...        ...        ...        ...   \n",
       "88699        0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "88700        0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "88701        0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "88702        0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "88703        0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       500101035  500101036  500101037  500101038  500101039  \n",
       "0            0.0        0.0        0.0        0.0        0.0  \n",
       "1            0.0        0.0        0.0        0.0        0.0  \n",
       "2            0.0        0.0        0.0        0.0        0.0  \n",
       "3            0.0        0.0        0.0        0.0        0.0  \n",
       "4            0.0        0.0        0.0        0.0        0.0  \n",
       "...          ...        ...        ...        ...        ...  \n",
       "88699        0.0        0.0        0.0        0.0        0.0  \n",
       "88700        0.0        0.0        0.0        0.0        0.0  \n",
       "88701        0.0        0.0        0.0        0.0        0.0  \n",
       "88702        0.0        0.0        0.0        0.0        0.0  \n",
       "88703        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[88704 rows x 44 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = submission.iloc[:,:44]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'time', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun',\n",
      "       '500101001', '500101002', '500101003', '500101004', '500101005',\n",
      "       '500101006', '500101007', '500101008', '500101009', '500101010',\n",
      "       '500101013', '500101014', '500101015', '500101018', '500101019',\n",
      "       '500101020', '500101021', '500101022', '500101023', '500101024',\n",
      "       '500101025', '500101026', '500101027', '500101028', '500101029',\n",
      "       '500101030', '500101031', '500101032', '500101033', '500101034',\n",
      "       '500101035', '500101036', '500101037', '500101038', '500101039'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "station_tot = {}\n",
    "print(submission.columns)\n",
    "for station in submission.columns[9:]:\n",
    "    find_tot = pd.read_json(f'html.2023.final.data/release/20231002/{station}.json', convert_axes=False)\n",
    "    find_tot = find_tot.transpose()\n",
    "    for n in find_tot['tot'].to_numpy():\n",
    "        try:\n",
    "            m = int(n)\n",
    "            TOT = n\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    station_tot[station] = TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/cns8rbyx5y17d2vn6gf6qkk80000gn/T/ipykernel_35684/2305658483.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  id = rows[1][0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 36 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/yl/HTML/final/predict_stage1.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/predict_stage1.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/predict_stage1.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m pred \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yl/HTML/final/predict_stage1.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39;49mitem()\u001b[39m*\u001b[39mstation_tot[station]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/predict_stage1.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m row\u001b[39m.\u001b[39mappend([\u001b[39mid\u001b[39m, pred])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/predict_stage1.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# remove row in df_orig_predict with id == id\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 36 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "model = torch.load('models/all')\n",
    "model.eval()\n",
    "#Net(\n",
    "#   (dropout): Dropout(p=0.30438527094835316, inplace=False)\n",
    "#   (fc1): Linear(in_features=43, out_features=538, bias=True)\n",
    "#   (fc2): Linear(in_features=538, out_features=538, bias=True)\n",
    "#   (fc3): Linear(in_features=538, out_features=538, bias=True)\n",
    "#   (fc4): Linear(in_features=538, out_features=538, bias=True)\n",
    "#   (fc5): Linear(in_features=538, out_features=1, bias=True)\n",
    "#   (relu): ReLU()\n",
    "# )\n",
    "df_orig_predict = pd.read_csv('predict/prediction_round.csv')\n",
    "row = []\n",
    "\n",
    "i= 0\n",
    "# iterate over each row in submission \n",
    "for rows in submission.iterrows():\n",
    "    # get first value of row\n",
    "    id = rows[1][0]\n",
    "    staion = id[9:18]\n",
    "    x = rows[1][1:]\n",
    "    x = x.values\n",
    "    x = x.astype(np.float32)\n",
    "    x = torch.tensor(x)\n",
    "    x = x.reshape(1, -1)\n",
    "    pred = model(x)\n",
    "    pred = pred.item()*station_tot[station]\n",
    "    row.append([id, pred])\n",
    "    # remove row in df_orig_predict with id == id\n",
    "    df_orig_predict = df_orig_predict[df_orig_predict['id'] != id]\n",
    "    # i += 1\n",
    "    # print(i)\n",
    "\n",
    "# append row to df_orig_predict\n",
    "row = pd.DataFrame(row, columns=['id', 'sbi'])\n",
    "df_orig_predict = df_orig_predict.append(row)\n",
    "df_orig_predict = df_orig_predict.sort_values(by=['id'])\n",
    "df_orig_predict.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "html-qsiNAWFM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
