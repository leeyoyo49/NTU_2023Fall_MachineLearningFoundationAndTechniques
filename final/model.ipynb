{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['500101001', '500101002', '500101003', '500101004', '500101005',\n",
       "       '500101006', '500101007', '500101008', '500101009', '500101010',\n",
       "       '500101013', '500101014', '500101015', '500101018', '500101019',\n",
       "       '500101020', '500101021', '500101022', '500101023', '500101024',\n",
       "       '500101025', '500101026', '500101027', '500101028', '500101029',\n",
       "       '500101030', '500101031', '500101032', '500101033', '500101034',\n",
       "       '500101035', '500101036', '500101037', '500101038', '500101039',\n",
       "       '500101040', '500101041', '500101042', '500101091', '500101092',\n",
       "       '500101093', '500101094', '500101114', '500101115', '500101123',\n",
       "       '500101166', '500101175', '500101176', '500101181', '500101184',\n",
       "       '500101185', '500101188', '500101189', '500101190', '500101191',\n",
       "       '500101193', '500101199', '500101209', '500101216', '500101219',\n",
       "       '500105066', '500106002', '500106003', '500106004', '500119043',\n",
       "       '500119044', '500119045', '500119046', '500119047', '500119048',\n",
       "       '500119049', '500119050', '500119051', '500119052', '500119053',\n",
       "       '500119054', '500119055', '500119056', '500119057', '500119058',\n",
       "       '500119059', '500119060', '500119061', '500119062', '500119063',\n",
       "       '500119064', '500119065', '500119066', '500119067', '500119068',\n",
       "       '500119069', '500119070', '500119071', '500119072', '500119074',\n",
       "       '500119075', '500119076', '500119077', '500119078', '500119079',\n",
       "       '500119080', '500119081', '500119082', '500119083', '500119084',\n",
       "       '500119085', '500119086', '500119087', '500119088', '500119089',\n",
       "       '500119090', '500119091'], dtype='<U9')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read sno_test_set.txt to available_station\n",
    "available_station = np.loadtxt('html.2023.final.data/sno_test_set.txt', dtype='str')\n",
    "available_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'html.2023.final.data/release'  # replace with your actual folder path\n",
    "available_date = os.listdir(folder_path)\n",
    "\n",
    "def get_one_hot_weekday(date_str):\n",
    "    # Convert the date string to a datetime object\n",
    "    date = datetime.datetime.strptime(date_str, '%Y%m%d')\n",
    "    \n",
    "    # Get the weekday (Monday is 0, Sunday is 6)\n",
    "    weekday = date.weekday()\n",
    "    \n",
    "    # Create a one-hot encoded list for the weekday\n",
    "    one_hot_weekday = [1 if i == weekday else 0 for i in range(7)]\n",
    "    \n",
    "    return one_hot_weekday\n",
    "\n",
    "def time_to_minute(time_str):\n",
    "    hours, minutes = map(int, time_str.split(':'))\n",
    "    total_minutes = hours * 60 + minutes\n",
    "    return total_minutes\n",
    "\n",
    "date_to_one_hot_weekday = {}\n",
    "for date in available_date:\n",
    "    date_to_one_hot_weekday[date] = [ x for x in get_one_hot_weekday(date)]\n",
    "\n",
    "sbis = []\n",
    "time = []\n",
    "feature_num = 8\n",
    "unit_time = 1\n",
    "one_hot_weekday = []\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "# for date in available_date:\n",
    "#     for station in available_station:\n",
    "#         df = pd.read_json(f'html.2023.final.data/release/{date}/{station}.json', convert_axes=False)\n",
    "#         df = df.transpose()\n",
    "#         df = df.bfill().ffill()\n",
    "#         df.reset_index(inplace=True)\n",
    "#         df = df.rename(columns={'index': 'time'})\n",
    "#         df['time'] = df['time'].apply(time_to_minute)\n",
    "#         df[['mon','tue','wed','thu','fri','sat','sun']] = [date_to_one_hot_weekday[date]] * len(df)\n",
    "#         df['station'] = [station] * len(df)\n",
    "#         dataset = pd.concat([dataset,df], ignore_index=False)\n",
    "\n",
    "using_station = 500101001\n",
    "for date in available_date:\n",
    "    df = pd.read_json(f'html.2023.final.data/release/{date}/{using_station}.json', convert_axes=False)\n",
    "    df = df.transpose()\n",
    "    df = df.bfill().ffill()\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns={'index': 'time'})\n",
    "    df['time'] = df['time'].apply(time_to_minute)\n",
    "    df[['mon','tue','wed','thu','fri','sat','sun']] = [date_to_one_hot_weekday[date]] * len(df)\n",
    "    df['station'] = [using_station] * len(df)\n",
    "    dataset = pd.concat([dataset,df], ignore_index=False)\n",
    "\n",
    "\n",
    "# pd.DataFrame.to_parquet(dataset, 'dataset.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'tot', 'sbi', 'bemp', 'act', 'mon', 'tue', 'wed', 'thu', 'fri',\n",
       "       'sat', 'sun', 'station'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yl/HTML/final/model.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m train_dataset, test_dataset \u001b[39m=\u001b[39m random_split(dataset, [train_size, test_size])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# get train, test loader\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m train_loader \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mDataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m test_loader \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mDataLoader(test_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# build the gradient boosting regression model with PyTorch\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "# get X, y\n",
    "df = pd.read_parquet('dataset.parquet')\n",
    "TOT = 28\n",
    "df['sbi'] = df['sbi']/TOT\n",
    "df['time'] = df['time']/1440\n",
    "\n",
    "# x is dataset without 'sbi', y is 'sbi'\n",
    "X = df.drop(['tot', 'sbi','bemp' ,'act', 'tot', 'station'], axis=1)\n",
    "y = df['sbi']\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# split train, test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# get train, test loader\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "# build the gradient boosting regression model with PyTorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        # Define your neural network here\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Define your neural network forward pass here\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, outputs, labels):\n",
    "        # Define your custom loss function here\n",
    "        # This is a simple example, replace it with your own function\n",
    "        custom_loss = 3*(torch.abs(labels - outputs))*(torch.abs(labels - 1/3) + torch.abs(labels -2/3))\n",
    "        return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72000, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.075271\n",
      "[1,   200] loss: 0.063514\n",
      "[1,   300] loss: 0.060414\n",
      "[1,   400] loss: 0.060102\n",
      "[2,   100] loss: 0.057716\n",
      "[2,   200] loss: 0.055509\n",
      "[2,   300] loss: 0.056227\n",
      "[2,   400] loss: 0.052882\n",
      "[3,   100] loss: 0.053319\n",
      "[3,   200] loss: 0.053719\n",
      "[3,   300] loss: 0.051929\n",
      "[3,   400] loss: 0.049346\n",
      "[4,   100] loss: 0.053319\n",
      "[4,   200] loss: 0.050084\n",
      "[4,   300] loss: 0.049915\n",
      "[4,   400] loss: 0.049289\n",
      "[5,   100] loss: 0.049340\n",
      "[5,   200] loss: 0.050421\n",
      "[5,   300] loss: 0.050711\n",
      "[5,   400] loss: 0.047059\n",
      "[6,   100] loss: 0.047375\n",
      "[6,   200] loss: 0.050172\n",
      "[6,   300] loss: 0.048488\n",
      "[6,   400] loss: 0.047017\n",
      "[7,   100] loss: 0.046906\n",
      "[7,   200] loss: 0.046000\n",
      "[7,   300] loss: 0.047288\n",
      "[7,   400] loss: 0.046695\n",
      "[8,   100] loss: 0.044679\n",
      "[8,   200] loss: 0.045952\n",
      "[8,   300] loss: 0.046293\n",
      "[8,   400] loss: 0.046046\n",
      "[9,   100] loss: 0.046606\n",
      "[9,   200] loss: 0.046594\n",
      "[9,   300] loss: 0.044800\n",
      "[9,   400] loss: 0.043674\n",
      "[10,   100] loss: 0.044780\n",
      "[10,   200] loss: 0.045059\n",
      "[10,   300] loss: 0.044047\n",
      "[10,   400] loss: 0.044456\n",
      "[11,   100] loss: 0.044747\n",
      "[11,   200] loss: 0.045696\n",
      "[11,   300] loss: 0.045992\n",
      "[11,   400] loss: 0.043934\n",
      "[12,   100] loss: 0.043739\n",
      "[12,   200] loss: 0.043360\n",
      "[12,   300] loss: 0.044577\n",
      "[12,   400] loss: 0.043131\n",
      "[13,   100] loss: 0.043902\n",
      "[13,   200] loss: 0.045769\n",
      "[13,   300] loss: 0.044475\n",
      "[13,   400] loss: 0.044132\n",
      "[14,   100] loss: 0.044263\n",
      "[14,   200] loss: 0.043037\n",
      "[14,   300] loss: 0.042889\n",
      "[14,   400] loss: 0.041878\n",
      "[15,   100] loss: 0.042635\n",
      "[15,   200] loss: 0.041415\n",
      "[15,   300] loss: 0.042552\n",
      "[15,   400] loss: 0.042217\n",
      "[16,   100] loss: 0.042525\n",
      "[16,   200] loss: 0.043584\n",
      "[16,   300] loss: 0.042469\n",
      "[16,   400] loss: 0.041535\n",
      "[17,   100] loss: 0.041271\n",
      "[17,   200] loss: 0.041810\n",
      "[17,   300] loss: 0.042720\n",
      "[17,   400] loss: 0.041703\n",
      "[18,   100] loss: 0.040808\n",
      "[18,   200] loss: 0.041980\n",
      "[18,   300] loss: 0.040375\n",
      "[18,   400] loss: 0.041566\n",
      "[19,   100] loss: 0.041130\n",
      "[19,   200] loss: 0.041941\n",
      "[19,   300] loss: 0.041333\n",
      "[19,   400] loss: 0.041803\n",
      "[20,   100] loss: 0.041528\n",
      "[20,   200] loss: 0.041556\n",
      "[20,   300] loss: 0.042011\n",
      "[20,   400] loss: 0.041867\n",
      "[21,   100] loss: 0.040272\n",
      "[21,   200] loss: 0.040046\n",
      "[21,   300] loss: 0.041254\n",
      "[21,   400] loss: 0.041609\n",
      "[22,   100] loss: 0.040617\n",
      "[22,   200] loss: 0.040433\n",
      "[22,   300] loss: 0.041174\n",
      "[22,   400] loss: 0.039746\n",
      "[23,   100] loss: 0.040808\n",
      "[23,   200] loss: 0.041092\n",
      "[23,   300] loss: 0.040647\n",
      "[23,   400] loss: 0.039276\n",
      "[24,   100] loss: 0.040566\n",
      "[24,   200] loss: 0.039641\n",
      "[24,   300] loss: 0.039517\n",
      "[24,   400] loss: 0.041750\n",
      "[25,   100] loss: 0.040847\n",
      "[25,   200] loss: 0.040152\n",
      "[25,   300] loss: 0.039185\n",
      "[25,   400] loss: 0.040606\n",
      "[26,   100] loss: 0.039738\n",
      "[26,   200] loss: 0.039857\n",
      "[26,   300] loss: 0.038931\n",
      "[26,   400] loss: 0.039858\n",
      "[27,   100] loss: 0.039868\n",
      "[27,   200] loss: 0.040159\n",
      "[27,   300] loss: 0.040119\n",
      "[27,   400] loss: 0.039060\n",
      "[28,   100] loss: 0.040688\n",
      "[28,   200] loss: 0.039383\n",
      "[28,   300] loss: 0.040210\n",
      "[28,   400] loss: 0.038766\n",
      "[29,   100] loss: 0.039217\n",
      "[29,   200] loss: 0.039256\n",
      "[29,   300] loss: 0.039905\n",
      "[29,   400] loss: 0.039374\n",
      "[30,   100] loss: 0.039552\n",
      "[30,   200] loss: 0.039933\n",
      "[30,   300] loss: 0.039652\n",
      "[30,   400] loss: 0.039087\n",
      "[31,   100] loss: 0.040040\n",
      "[31,   200] loss: 0.039471\n",
      "[31,   300] loss: 0.039540\n",
      "[31,   400] loss: 0.039144\n",
      "[32,   100] loss: 0.038408\n",
      "[32,   200] loss: 0.038816\n",
      "[32,   300] loss: 0.038629\n",
      "[32,   400] loss: 0.039773\n",
      "[33,   100] loss: 0.039269\n",
      "[33,   200] loss: 0.038868\n",
      "[33,   300] loss: 0.039086\n",
      "[33,   400] loss: 0.039640\n",
      "[34,   100] loss: 0.038384\n",
      "[34,   200] loss: 0.039095\n",
      "[34,   300] loss: 0.038767\n",
      "[34,   400] loss: 0.038247\n",
      "[35,   100] loss: 0.037803\n",
      "[35,   200] loss: 0.039251\n",
      "[35,   300] loss: 0.039408\n",
      "[35,   400] loss: 0.039102\n",
      "[36,   100] loss: 0.038008\n",
      "[36,   200] loss: 0.039157\n",
      "[36,   300] loss: 0.037616\n",
      "[36,   400] loss: 0.040035\n",
      "[37,   100] loss: 0.037737\n",
      "[37,   200] loss: 0.038363\n",
      "[37,   300] loss: 0.040248\n",
      "[37,   400] loss: 0.037957\n",
      "[38,   100] loss: 0.039004\n",
      "[38,   200] loss: 0.038320\n",
      "[38,   300] loss: 0.038466\n",
      "[38,   400] loss: 0.039195\n",
      "[39,   100] loss: 0.038811\n",
      "[39,   200] loss: 0.038264\n",
      "[39,   300] loss: 0.038399\n",
      "[39,   400] loss: 0.038993\n",
      "[40,   100] loss: 0.039102\n",
      "[40,   200] loss: 0.038482\n",
      "[40,   300] loss: 0.038732\n",
      "[40,   400] loss: 0.038316\n",
      "[41,   100] loss: 0.038511\n",
      "[41,   200] loss: 0.038473\n",
      "[41,   300] loss: 0.038951\n",
      "[41,   400] loss: 0.038137\n",
      "[42,   100] loss: 0.038957\n",
      "[42,   200] loss: 0.038779\n",
      "[42,   300] loss: 0.038286\n",
      "[42,   400] loss: 0.037904\n",
      "[43,   100] loss: 0.037734\n",
      "[43,   200] loss: 0.038282\n",
      "[43,   300] loss: 0.038237\n",
      "[43,   400] loss: 0.038444\n",
      "[44,   100] loss: 0.038917\n",
      "[44,   200] loss: 0.037659\n",
      "[44,   300] loss: 0.037822\n",
      "[44,   400] loss: 0.037798\n",
      "[45,   100] loss: 0.037146\n",
      "[45,   200] loss: 0.038666\n",
      "[45,   300] loss: 0.037917\n",
      "[45,   400] loss: 0.037061\n",
      "[46,   100] loss: 0.037626\n",
      "[46,   200] loss: 0.038901\n",
      "[46,   300] loss: 0.038326\n",
      "[46,   400] loss: 0.037100\n",
      "[47,   100] loss: 0.038881\n",
      "[47,   200] loss: 0.037899\n",
      "[47,   300] loss: 0.037782\n",
      "[47,   400] loss: 0.038188\n",
      "[48,   100] loss: 0.038741\n",
      "[48,   200] loss: 0.037310\n",
      "[48,   300] loss: 0.037765\n",
      "[48,   400] loss: 0.037314\n",
      "[49,   100] loss: 0.038065\n",
      "[49,   200] loss: 0.038937\n",
      "[49,   300] loss: 0.037053\n",
      "[49,   400] loss: 0.037707\n",
      "[50,   100] loss: 0.038486\n",
      "[50,   200] loss: 0.038035\n",
      "[50,   300] loss: 0.037289\n",
      "[50,   400] loss: 0.037576\n",
      "[51,   100] loss: 0.038955\n",
      "[51,   200] loss: 0.037342\n",
      "[51,   300] loss: 0.037582\n",
      "[51,   400] loss: 0.038329\n",
      "[52,   100] loss: 0.038411\n",
      "[52,   200] loss: 0.037359\n",
      "[52,   300] loss: 0.037616\n",
      "[52,   400] loss: 0.038173\n",
      "[53,   100] loss: 0.037809\n",
      "[53,   200] loss: 0.037684\n",
      "[53,   300] loss: 0.037096\n",
      "[53,   400] loss: 0.038049\n",
      "[54,   100] loss: 0.037744\n",
      "[54,   200] loss: 0.038010\n",
      "[54,   300] loss: 0.038406\n",
      "[54,   400] loss: 0.038767\n",
      "[55,   100] loss: 0.037401\n",
      "[55,   200] loss: 0.037663\n",
      "[55,   300] loss: 0.038399\n",
      "[55,   400] loss: 0.037322\n",
      "[56,   100] loss: 0.037411\n",
      "[56,   200] loss: 0.038380\n",
      "[56,   300] loss: 0.037054\n",
      "[56,   400] loss: 0.037148\n",
      "[57,   100] loss: 0.038755\n",
      "[57,   200] loss: 0.036428\n",
      "[57,   300] loss: 0.037823\n",
      "[57,   400] loss: 0.037301\n",
      "[58,   100] loss: 0.038296\n",
      "[58,   200] loss: 0.037515\n",
      "[58,   300] loss: 0.037587\n",
      "[58,   400] loss: 0.037196\n",
      "[59,   100] loss: 0.037544\n",
      "[59,   200] loss: 0.037039\n",
      "[59,   300] loss: 0.038369\n",
      "[59,   400] loss: 0.037441\n",
      "[60,   100] loss: 0.037042\n",
      "[60,   200] loss: 0.038520\n",
      "[60,   300] loss: 0.036375\n",
      "[60,   400] loss: 0.037290\n",
      "[61,   100] loss: 0.038236\n",
      "[61,   200] loss: 0.037891\n",
      "[61,   300] loss: 0.037216\n",
      "[61,   400] loss: 0.037286\n",
      "[62,   100] loss: 0.036542\n",
      "[62,   200] loss: 0.037043\n",
      "[62,   300] loss: 0.038651\n",
      "[62,   400] loss: 0.036766\n",
      "[63,   100] loss: 0.037984\n",
      "[63,   200] loss: 0.037427\n",
      "[63,   300] loss: 0.037255\n",
      "[63,   400] loss: 0.037330\n",
      "[64,   100] loss: 0.037861\n",
      "[64,   200] loss: 0.037078\n",
      "[64,   300] loss: 0.037364\n",
      "[64,   400] loss: 0.037294\n",
      "[65,   100] loss: 0.037198\n",
      "[65,   200] loss: 0.037765\n",
      "[65,   300] loss: 0.037299\n",
      "[65,   400] loss: 0.036494\n",
      "[66,   100] loss: 0.039283\n",
      "[66,   200] loss: 0.036697\n",
      "[66,   300] loss: 0.037211\n",
      "[66,   400] loss: 0.037158\n",
      "[67,   100] loss: 0.036841\n",
      "[67,   200] loss: 0.037644\n",
      "[67,   300] loss: 0.036843\n",
      "[67,   400] loss: 0.036987\n",
      "[68,   100] loss: 0.037480\n",
      "[68,   200] loss: 0.036529\n",
      "[68,   300] loss: 0.036916\n",
      "[68,   400] loss: 0.037839\n",
      "[69,   100] loss: 0.036942\n",
      "[69,   200] loss: 0.037854\n",
      "[69,   300] loss: 0.037053\n",
      "[69,   400] loss: 0.037731\n",
      "[70,   100] loss: 0.037534\n",
      "[70,   200] loss: 0.038390\n",
      "[70,   300] loss: 0.036638\n",
      "[70,   400] loss: 0.037554\n",
      "[71,   100] loss: 0.036903\n",
      "[71,   200] loss: 0.037548\n",
      "[71,   300] loss: 0.036918\n",
      "[71,   400] loss: 0.037548\n",
      "[72,   100] loss: 0.036722\n",
      "[72,   200] loss: 0.037464\n",
      "[72,   300] loss: 0.036850\n",
      "[72,   400] loss: 0.036715\n",
      "[73,   100] loss: 0.037317\n",
      "[73,   200] loss: 0.036861\n",
      "[73,   300] loss: 0.036415\n",
      "[73,   400] loss: 0.038029\n",
      "[74,   100] loss: 0.036138\n",
      "[74,   200] loss: 0.038429\n",
      "[74,   300] loss: 0.036830\n",
      "[74,   400] loss: 0.037325\n",
      "[75,   100] loss: 0.037907\n",
      "[75,   200] loss: 0.036965\n",
      "[75,   300] loss: 0.035845\n",
      "[75,   400] loss: 0.037169\n",
      "[76,   100] loss: 0.037387\n",
      "[76,   200] loss: 0.037422\n",
      "[76,   300] loss: 0.037224\n",
      "[76,   400] loss: 0.036760\n",
      "[77,   100] loss: 0.036718\n",
      "[77,   200] loss: 0.037156\n",
      "[77,   300] loss: 0.037268\n",
      "[77,   400] loss: 0.036995\n",
      "[78,   100] loss: 0.036706\n",
      "[78,   200] loss: 0.036703\n",
      "[78,   300] loss: 0.037425\n",
      "[78,   400] loss: 0.036986\n",
      "[79,   100] loss: 0.037223\n",
      "[79,   200] loss: 0.036725\n",
      "[79,   300] loss: 0.036714\n",
      "[79,   400] loss: 0.036223\n",
      "[80,   100] loss: 0.036748\n",
      "[80,   200] loss: 0.037520\n",
      "[80,   300] loss: 0.036600\n",
      "[80,   400] loss: 0.036926\n",
      "[81,   100] loss: 0.036701\n",
      "[81,   200] loss: 0.038914\n",
      "[81,   300] loss: 0.035319\n",
      "[81,   400] loss: 0.037538\n",
      "[82,   100] loss: 0.037239\n",
      "[82,   200] loss: 0.037375\n",
      "[82,   300] loss: 0.036040\n",
      "[82,   400] loss: 0.038057\n",
      "[83,   100] loss: 0.037400\n",
      "[83,   200] loss: 0.036742\n",
      "[83,   300] loss: 0.036602\n",
      "[83,   400] loss: 0.037269\n",
      "[84,   100] loss: 0.036597\n",
      "[84,   200] loss: 0.037190\n",
      "[84,   300] loss: 0.036289\n",
      "[84,   400] loss: 0.036263\n",
      "[85,   100] loss: 0.037445\n",
      "[85,   200] loss: 0.036924\n",
      "[85,   300] loss: 0.036200\n",
      "[85,   400] loss: 0.036611\n",
      "[86,   100] loss: 0.036918\n",
      "[86,   200] loss: 0.036438\n",
      "[86,   300] loss: 0.036792\n",
      "[86,   400] loss: 0.036538\n",
      "[87,   100] loss: 0.036189\n",
      "[87,   200] loss: 0.036587\n",
      "[87,   300] loss: 0.037036\n",
      "[87,   400] loss: 0.036751\n",
      "[88,   100] loss: 0.036981\n",
      "[88,   200] loss: 0.037716\n",
      "[88,   300] loss: 0.036325\n",
      "[88,   400] loss: 0.036161\n",
      "[89,   100] loss: 0.036661\n",
      "[89,   200] loss: 0.036487\n",
      "[89,   300] loss: 0.036699\n",
      "[89,   400] loss: 0.038044\n",
      "[90,   100] loss: 0.036447\n",
      "[90,   200] loss: 0.037152\n",
      "[90,   300] loss: 0.036601\n",
      "[90,   400] loss: 0.037237\n",
      "[91,   100] loss: 0.036800\n",
      "[91,   200] loss: 0.038007\n",
      "[91,   300] loss: 0.036986\n",
      "[91,   400] loss: 0.036555\n",
      "[92,   100] loss: 0.037229\n",
      "[92,   200] loss: 0.036767\n",
      "[92,   300] loss: 0.036660\n",
      "[92,   400] loss: 0.036433\n",
      "[93,   100] loss: 0.037179\n",
      "[93,   200] loss: 0.037154\n",
      "[93,   300] loss: 0.036066\n",
      "[93,   400] loss: 0.036578\n",
      "[94,   100] loss: 0.036691\n",
      "[94,   200] loss: 0.036639\n",
      "[94,   300] loss: 0.036902\n",
      "[94,   400] loss: 0.036742\n",
      "[95,   100] loss: 0.036579\n",
      "[95,   200] loss: 0.036267\n",
      "[95,   300] loss: 0.036110\n",
      "[95,   400] loss: 0.036404\n",
      "[96,   100] loss: 0.036561\n",
      "[96,   200] loss: 0.037323\n",
      "[96,   300] loss: 0.036749\n",
      "[96,   400] loss: 0.036379\n",
      "[97,   100] loss: 0.036599\n",
      "[97,   200] loss: 0.037361\n",
      "[97,   300] loss: 0.037193\n",
      "[97,   400] loss: 0.036583\n",
      "[98,   100] loss: 0.037609\n",
      "[98,   200] loss: 0.036980\n",
      "[98,   300] loss: 0.036188\n",
      "[98,   400] loss: 0.036528\n",
      "[99,   100] loss: 0.036492\n",
      "[99,   200] loss: 0.037371\n",
      "[99,   300] loss: 0.037142\n",
      "[99,   400] loss: 0.036521\n",
      "[100,   100] loss: 0.036608\n",
      "[100,   200] loss: 0.036499\n",
      "[100,   300] loss: 0.036446\n",
      "[100,   400] loss: 0.037176\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model = Net(8, 4096, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.reshape(-1)\n",
    "        loss = criterion(outputs, labels).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 loss: 0.247001\n",
      "batch 2 loss: 0.305211\n",
      "batch 3 loss: 0.264058\n",
      "batch 4 loss: 0.276309\n",
      "batch 5 loss: 0.266097\n",
      "batch 6 loss: 0.298638\n",
      "batch 7 loss: 0.275172\n",
      "batch 8 loss: 0.312751\n",
      "batch 9 loss: 0.251341\n",
      "batch 10 loss: 0.291081\n",
      "batch 11 loss: 0.271888\n",
      "batch 12 loss: 0.236799\n",
      "batch 13 loss: 0.264099\n",
      "batch 14 loss: 0.301312\n",
      "batch 15 loss: 0.271257\n",
      "batch 16 loss: 0.270566\n",
      "batch 17 loss: 0.283505\n",
      "batch 18 loss: 0.294367\n",
      "batch 19 loss: 0.258521\n",
      "batch 20 loss: 0.273198\n",
      "batch 21 loss: 0.247406\n",
      "batch 22 loss: 0.274148\n",
      "batch 23 loss: 0.282783\n",
      "batch 24 loss: 0.269160\n",
      "batch 25 loss: 0.268907\n",
      "batch 26 loss: 0.284202\n",
      "batch 27 loss: 0.280383\n",
      "batch 28 loss: 0.281709\n",
      "batch 29 loss: 0.287912\n",
      "batch 30 loss: 0.282800\n",
      "batch 31 loss: 0.286821\n",
      "batch 32 loss: 0.248958\n",
      "batch 33 loss: 0.244954\n",
      "batch 34 loss: 0.307432\n",
      "batch 35 loss: 0.316979\n",
      "batch 36 loss: 0.261991\n",
      "batch 37 loss: 0.262702\n",
      "batch 38 loss: 0.262284\n",
      "batch 39 loss: 0.322188\n",
      "batch 40 loss: 0.239256\n",
      "batch 41 loss: 0.258613\n",
      "batch 42 loss: 0.256980\n",
      "batch 43 loss: 0.318206\n",
      "batch 44 loss: 0.289307\n",
      "batch 45 loss: 0.279725\n",
      "batch 46 loss: 0.300666\n",
      "batch 47 loss: 0.262204\n",
      "batch 48 loss: 0.336895\n",
      "batch 49 loss: 0.248585\n",
      "batch 50 loss: 0.299836\n",
      "batch 51 loss: 0.280267\n",
      "batch 52 loss: 0.284210\n",
      "batch 53 loss: 0.274197\n",
      "batch 54 loss: 0.292195\n",
      "batch 55 loss: 0.299523\n",
      "batch 56 loss: 0.252964\n",
      "batch 57 loss: 0.252360\n",
      "batch 58 loss: 0.288966\n",
      "batch 59 loss: 0.252722\n",
      "batch 60 loss: 0.287416\n",
      "batch 61 loss: 0.295998\n",
      "batch 62 loss: 0.234654\n",
      "batch 63 loss: 0.243410\n",
      "batch 64 loss: 0.265906\n",
      "batch 65 loss: 0.294455\n",
      "batch 66 loss: 0.312698\n",
      "batch 67 loss: 0.274640\n",
      "batch 68 loss: 0.273996\n",
      "batch 69 loss: 0.294781\n",
      "batch 70 loss: 0.285237\n",
      "batch 71 loss: 0.278240\n",
      "batch 72 loss: 0.273336\n",
      "batch 73 loss: 0.283587\n",
      "batch 74 loss: 0.280205\n",
      "batch 75 loss: 0.244806\n",
      "batch 76 loss: 0.227769\n",
      "batch 77 loss: 0.278311\n",
      "batch 78 loss: 0.268707\n",
      "batch 79 loss: 0.287089\n",
      "batch 80 loss: 0.296136\n",
      "batch 81 loss: 0.259806\n",
      "batch 82 loss: 0.247621\n",
      "batch 83 loss: 0.292707\n",
      "batch 84 loss: 0.310789\n",
      "batch 85 loss: 0.286384\n",
      "batch 86 loss: 0.281744\n",
      "batch 87 loss: 0.267681\n",
      "batch 88 loss: 0.250899\n",
      "batch 89 loss: 0.295758\n",
      "batch 90 loss: 0.236412\n",
      "batch 91 loss: 0.256643\n",
      "batch 92 loss: 0.222068\n",
      "batch 93 loss: 0.276904\n",
      "batch 94 loss: 0.304097\n",
      "batch 95 loss: 0.256365\n",
      "batch 96 loss: 0.257805\n",
      "batch 97 loss: 0.288225\n",
      "batch 98 loss: 0.275188\n",
      "batch 99 loss: 0.272297\n",
      "batch 100 loss: 0.350553\n",
      "batch 101 loss: 0.292658\n",
      "batch 102 loss: 0.246597\n",
      "batch 103 loss: 0.253117\n",
      "batch 104 loss: 0.279362\n",
      "batch 105 loss: 0.275859\n",
      "batch 106 loss: 0.276405\n",
      "batch 107 loss: 0.293797\n",
      "batch 108 loss: 0.279543\n",
      "batch 109 loss: 0.247497\n",
      "batch 110 loss: 0.251136\n",
      "batch 111 loss: 0.278830\n",
      "batch 112 loss: 0.325076\n",
      "batch 113 loss: 0.257818\n",
      "total loss: 0.276042\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "# calculate with custom loss\n",
    "def custom_error(outputs, labels):\n",
    "    return 3*(torch.abs(labels - outputs))*(torch.abs(labels - 1/3) + torch.abs(labels -2/3))\n",
    "\n",
    "total_loss = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.float()\n",
    "    labels = labels.float()\n",
    "    outputs = model(inputs).reshape(-1)\n",
    "    # use custom loss\n",
    "    loss = custom_error(outputs, labels).sum()\n",
    "    total_loss += loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = t1.detach().numpy()\n",
    "t2 = t2.detach().numpy()\n",
    "plt.plot(t1, label='predict', color = 'red')\n",
    "plt.plot(t2, label='real', color = 'blue')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['500101001', '500101002', '500101003', '500101004', '500101005',\n",
       "       '500101006', '500101007', '500101008', '500101009', '500101010',\n",
       "       '500101013', '500101014', '500101015', '500101018', '500101019',\n",
       "       '500101020', '500101021', '500101022', '500101023', '500101024',\n",
       "       '500101025', '500101026', '500101027', '500101028', '500101029',\n",
       "       '500101030', '500101031', '500101032', '500101033', '500101034',\n",
       "       '500101035', '500101036', '500101037', '500101038', '500101039'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first35_station = available_station[:35]\n",
    "first35_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X, y\n",
    "df = pd.read_parquet('dataset.parquet')\n",
    "TOT = 28\n",
    "df['sbi'] = df['sbi']/TOT\n",
    "df['time'] = df['time']/1440\n",
    "\n",
    "# x is dataset without 'sbi', y is 'sbi'\n",
    "X = df.drop(['tot', 'sbi','bemp' ,'act', 'tot', 'station'], axis=1)\n",
    "y = df['sbi']\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# split train, test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# get train, test loader\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# build the gradient boosting regression model with PyTorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, outputs, labels):\n",
    "        # Define your custom loss function here\n",
    "        # This is a simple example, replace it with your own function\n",
    "        custom_loss = 3*(torch.abs(labels - outputs))*(torch.abs(labels - 1/3) + torch.abs(labels -2/3))\n",
    "        return custom_loss\n",
    "\n",
    "\n",
    "# ...\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    input_size = 8\n",
    "    hidden_size = trial.suggest_int('hidden_size', 3, 10000, log=True)  # Single hidden size for all layers\n",
    "    output_size = 1\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e1, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.7)\n",
    "\n",
    "    # Instantiate the model with sampled hyperparameters\n",
    "    model = Net(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = CustomLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(100):\n",
    "        training_loss = 0.0\n",
    "        eval_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.reshape(-1)\n",
    "            loss = criterion(outputs, labels).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        # Iterate over the DataLoader for test data\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                outputs = model(inputs).reshape(-1)\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                eval_loss += loss\n",
    "\n",
    "        # Optuna logs the running loss for each epoch\n",
    "        trial.report(eval_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Return the running loss as the objective value to minimize\n",
    "    return eval_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 14:42:40,342] A new study created in RDB with name: 500101001\n",
      "[I 2023-12-01 14:43:08,120] Trial 0 finished with value: 5764.0732421875 and parameters: {'num_layers': 3, 'hidden_size': 57, 'learning_rate': 0.8167306877837324, 'dropout_rate': 0.5926224981861072}. Best is trial 0 with value: 5764.0732421875.\n",
      "[I 2023-12-01 14:43:35,609] Trial 1 finished with value: 5747.6533203125 and parameters: {'num_layers': 4, 'hidden_size': 36, 'learning_rate': 0.11917838822404833, 'dropout_rate': 0.3322119590000635}. Best is trial 1 with value: 5747.6533203125.\n",
      "[I 2023-12-01 14:45:09,207] Trial 2 finished with value: 5777.17626953125 and parameters: {'num_layers': 5, 'hidden_size': 4727, 'learning_rate': 2.5416736760696947, 'dropout_rate': 0.5629634422738523}. Best is trial 1 with value: 5747.6533203125.\n",
      "[I 2023-12-01 14:46:04,123] Trial 3 finished with value: 3742.68505859375 and parameters: {'num_layers': 2, 'hidden_size': 2259, 'learning_rate': 0.00031133154510835047, 'dropout_rate': 0.11438432117624207}. Best is trial 3 with value: 3742.68505859375.\n",
      "[I 2023-12-01 14:46:37,541] Trial 4 finished with value: 4247.46240234375 and parameters: {'num_layers': 2, 'hidden_size': 286, 'learning_rate': 0.031607119298835064, 'dropout_rate': 0.26258111029083114}. Best is trial 3 with value: 3742.68505859375.\n",
      "[I 2023-12-01 14:46:37,906] Trial 5 pruned. \n",
      "[I 2023-12-01 14:47:32,309] Trial 6 finished with value: 4516.65478515625 and parameters: {'num_layers': 1, 'hidden_size': 2165, 'learning_rate': 1.1084769426036093e-05, 'dropout_rate': 0.2983807028491504}. Best is trial 3 with value: 3742.68505859375.\n",
      "[I 2023-12-01 14:47:32,587] Trial 7 pruned. \n",
      "[I 2023-12-01 14:47:59,978] Trial 8 finished with value: 3795.99951171875 and parameters: {'num_layers': 1, 'hidden_size': 200, 'learning_rate': 0.005172766215300373, 'dropout_rate': 0.6961923065626654}. Best is trial 3 with value: 3742.68505859375.\n",
      "[I 2023-12-01 14:48:00,444] Trial 9 pruned. \n",
      "[I 2023-12-01 14:50:08,988] Trial 10 finished with value: 3529.008056640625 and parameters: {'num_layers': 2, 'hidden_size': 8221, 'learning_rate': 0.00032515618389964123, 'dropout_rate': 0.05144338674751242}. Best is trial 10 with value: 3529.008056640625.\n",
      "[I 2023-12-01 14:52:41,743] Trial 11 finished with value: 3554.129150390625 and parameters: {'num_layers': 2, 'hidden_size': 9655, 'learning_rate': 0.0004956175432462072, 'dropout_rate': 0.04862727140053419}. Best is trial 10 with value: 3529.008056640625.\n",
      "[I 2023-12-01 14:54:32,545] Trial 12 finished with value: 3520.953369140625 and parameters: {'num_layers': 2, 'hidden_size': 6157, 'learning_rate': 0.0007085963207893594, 'dropout_rate': 0.009930362473345111}. Best is trial 12 with value: 3520.953369140625.\n",
      "[I 2023-12-01 14:54:33,343] Trial 13 pruned. \n",
      "[I 2023-12-01 14:54:36,632] Trial 14 pruned. \n",
      "[I 2023-12-01 14:54:37,225] Trial 15 pruned. \n",
      "[I 2023-12-01 14:55:47,580] Trial 16 finished with value: 3516.80419921875 and parameters: {'num_layers': 2, 'hidden_size': 3376, 'learning_rate': 0.0029403555426387768, 'dropout_rate': 0.0018062640232380939}. Best is trial 16 with value: 3516.80419921875.\n",
      "[I 2023-12-01 14:56:16,163] Trial 17 pruned. \n",
      "[I 2023-12-01 14:56:16,751] Trial 18 pruned. \n",
      "[I 2023-12-01 14:56:18,613] Trial 19 pruned. \n",
      "[I 2023-12-01 14:56:57,081] Trial 20 finished with value: 3547.919189453125 and parameters: {'num_layers': 3, 'hidden_size': 908, 'learning_rate': 0.0017793370161124167, 'dropout_rate': 0.18058616833717275}. Best is trial 16 with value: 3516.80419921875.\n",
      "[I 2023-12-01 14:57:00,059] Trial 21 pruned. \n",
      "[I 2023-12-01 14:58:19,888] Trial 22 finished with value: 3538.852783203125 and parameters: {'num_layers': 2, 'hidden_size': 3913, 'learning_rate': 0.0009250501950974108, 'dropout_rate': 0.06178462855906586}. Best is trial 16 with value: 3516.80419921875.\n",
      "[I 2023-12-01 14:58:26,919] Trial 23 pruned. \n",
      "[I 2023-12-01 14:59:48,794] Trial 24 finished with value: 3557.92431640625 and parameters: {'num_layers': 2, 'hidden_size': 4242, 'learning_rate': 0.0010859700019987136, 'dropout_rate': 0.08158783222539401}. Best is trial 16 with value: 3516.80419921875.\n",
      "[I 2023-12-01 14:59:59,252] Trial 25 pruned. \n",
      "[I 2023-12-01 15:00:02,677] Trial 26 pruned. \n",
      "[I 2023-12-01 15:00:04,363] Trial 27 pruned. \n",
      "[I 2023-12-01 15:00:05,242] Trial 28 pruned. \n",
      "[I 2023-12-01 15:00:07,819] Trial 29 pruned. \n",
      "[I 2023-12-01 15:00:09,082] Trial 30 pruned. \n",
      "[I 2023-12-01 15:00:12,646] Trial 31 pruned. \n",
      "[I 2023-12-01 15:00:15,075] Trial 32 pruned. \n",
      "[I 2023-12-01 15:00:17,978] Trial 33 pruned. \n",
      "[I 2023-12-01 15:00:26,486] Trial 34 pruned. \n",
      "[I 2023-12-01 15:00:27,522] Trial 35 pruned. \n",
      "[I 2023-12-01 15:00:41,995] Trial 36 pruned. \n",
      "[I 2023-12-01 15:00:44,405] Trial 37 pruned. \n",
      "[I 2023-12-01 15:00:46,246] Trial 38 pruned. \n",
      "[I 2023-12-01 15:01:04,110] Trial 39 pruned. \n",
      "[I 2023-12-01 15:01:04,608] Trial 40 pruned. \n",
      "[I 2023-12-01 15:01:05,250] Trial 41 pruned. \n",
      "[I 2023-12-01 15:01:55,985] Trial 42 finished with value: 3576.958984375 and parameters: {'num_layers': 3, 'hidden_size': 1899, 'learning_rate': 0.0014549965827347375, 'dropout_rate': 0.06779796176448125}. Best is trial 16 with value: 3516.80419921875.\n",
      "[I 2023-12-01 15:01:57,098] Trial 43 pruned. \n",
      "[I 2023-12-01 15:02:08,859] Trial 44 pruned. \n",
      "[I 2023-12-01 15:02:15,155] Trial 45 pruned. \n",
      "[I 2023-12-01 15:02:28,738] Trial 46 pruned. \n",
      "[I 2023-12-01 15:02:29,468] Trial 47 pruned. \n",
      "[I 2023-12-01 15:02:31,244] Trial 48 pruned. \n",
      "[I 2023-12-01 15:02:32,304] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_layers': 2, 'hidden_size': 3376, 'learning_rate': 0.0029403555426387768, 'dropout_rate': 0.0018062640232380939}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Net.__init__() missing 3 required positional arguments: 'hidden_size', 'output_size', and 'dropout_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yl/HTML/final/model.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest hyperparameters:\u001b[39m\u001b[39m'\u001b[39m, best_params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Instantiate the final model with the best hyperparameters\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m final_model \u001b[39m=\u001b[39m Net(best_params\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Train the final model with the entire dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# (You might want to reinitialize the optimizer with the best learning rate here)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# ... rest of your training code for the final model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m criterion \u001b[39m=\u001b[39m CustomLoss()\n",
      "\u001b[0;31mTypeError\u001b[0m: Net.__init__() missing 3 required positional arguments: 'hidden_size', 'output_size', and 'dropout_rate'"
     ]
    }
   ],
   "source": [
    "# Create an Optuna Study\n",
    "using_station = 500101001\n",
    "study = optuna.create_study(direction='minimize', storage='sqlite:///db.sqlite3', study_name=f'{using_station}')\n",
    "\n",
    "# Run the optimization process\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Access the best hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "print('Best hyperparameters:', best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['num_layers', 'hidden_size', 'learning_rate', 'dropout_rate'])\n",
      "epoch: 0, loss: 0.3635465969359684\n",
      "epoch: 1, loss: 0.31035925479701737\n",
      "epoch: 2, loss: 0.29165332006095357\n",
      "epoch: 3, loss: 0.2840844672537189\n",
      "epoch: 4, loss: 0.27951406839685794\n",
      "epoch: 5, loss: 0.2757081785115213\n",
      "epoch: 6, loss: 0.27502642725437193\n",
      "epoch: 7, loss: 0.27392134311250005\n",
      "epoch: 8, loss: 0.271901988472333\n",
      "epoch: 9, loss: 0.2708220649411369\n",
      "epoch: 10, loss: 0.2701147651005384\n",
      "epoch: 11, loss: 0.2695456630753793\n",
      "epoch: 12, loss: 0.2698515879642053\n",
      "epoch: 13, loss: 0.2688152865501746\n",
      "epoch: 14, loss: 0.2686289425800368\n",
      "epoch: 15, loss: 0.26774531332891743\n",
      "epoch: 16, loss: 0.2665735161854996\n",
      "epoch: 17, loss: 0.2667158149434237\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yl/HTML/final/model.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(all_data_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 620\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/torch/utils/data/sampler.py:282\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m batch \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    281\u001b[0m idx_in_batch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 282\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler:\n\u001b[1;32m    283\u001b[0m     batch[idx_in_batch] \u001b[39m=\u001b[39m idx\n\u001b[1;32m    284\u001b[0m     idx_in_batch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/torch/utils/data/sampler.py:165\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n):\n\u001b[1;32m    164\u001b[0m     \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39mrandperm(n, generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m--> 165\u001b[0m \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39;49mrandperm(n, generator\u001b[39m=\u001b[39;49mgenerator)\u001b[39m.\u001b[39;49mtolist()[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m%\u001b[39m n]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get X, y\n",
    "df = pd.read_parquet('dataset.parquet')\n",
    "TOT = 28\n",
    "df['sbi'] = df['sbi']/TOT\n",
    "df['time'] = df['time']/1440\n",
    "\n",
    "# x is dataset without 'sbi', y is 'sbi'\n",
    "X = df.drop(['tot', 'sbi','bemp' ,'act', 'tot', 'station'], axis=1)\n",
    "y = df['sbi']\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# get train, test loader\n",
    "all_data_loader = torch.utils.data.DataLoader(dataset, batch_size = 128, shuffle=True)\n",
    "\n",
    "# Instantiate the final model with the best hyperparameters\n",
    "print(best_params.keys())\n",
    "final_model = Net(8, best_params['hidden_size'], 1, best_params['dropout_rate'])\n",
    "\n",
    "# ... rest of your training code for the final model\n",
    "criterion = CustomLoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "# train with whole dataset\n",
    "running_loss = 0.0\n",
    "for epoch in range(20):\n",
    "    for i, data in enumerate(all_data_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = criterion(outputs, labels).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()/128\n",
    "    print(f'epoch: {epoch+1}, loss: {running_loss/all_data_loader.__len__()}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "final_model.eval()\n",
    "# save model\n",
    "torch.save(final_model.state_dict(), f'models/model_{using_station}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class station_model():\n",
    "    def __init__(self, station):\n",
    "        self.station = station\n",
    "\n",
    "    def get_data_loader(self):\n",
    "        df = pd.read_parquet(f'parquets/{self.station}.parquet')\n",
    "        TOT = df['tot'].iloc[0]\n",
    "        df['sbi'] = df['sbi']/TOT\n",
    "        df['time'] = df['time']/1440\n",
    "\n",
    "        # x is dataset without 'sbi', y is 'sbi'\n",
    "        X = df.drop(['tot', 'sbi','bemp' ,'act', 'tot', 'station'], axis=1)\n",
    "        y = df['sbi']\n",
    "\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "\n",
    "        X = torch.from_numpy(X)\n",
    "        y = torch.from_numpy(y)\n",
    "        dataset = TensorDataset(X, y)\n",
    "\n",
    "        # get train, test loader\n",
    "        self.all_data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # split train, test\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        # get train, test loader\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "        print(f'get data loader for {self.station}')\n",
    "\n",
    "    def objective(self,trial):\n",
    "        # Sample hyperparameters\n",
    "        input_size = 8\n",
    "        hidden_size = trial.suggest_int('hidden_size', 3, 10000, log=True)  # Single hidden size for all layers\n",
    "        output_size = 1\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e1, log=True)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.7)\n",
    "\n",
    "        # Instantiate the model with sampled hyperparameters\n",
    "        model = Net(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = CustomLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(100):\n",
    "            training_loss = 0.0\n",
    "            eval_loss = 0.0\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.reshape(-1)\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.item()\n",
    "\n",
    "            model.eval()\n",
    "            # Iterate over the DataLoader for test data\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(self.test_loader):\n",
    "                    inputs, labels = data\n",
    "                    inputs = inputs.float()\n",
    "                    labels = labels.float()\n",
    "                    outputs = model(inputs).reshape(-1)\n",
    "                    loss = criterion(outputs, labels).sum()\n",
    "                    eval_loss += loss\n",
    "\n",
    "            # Optuna logs the running loss for each epoch\n",
    "            trial.report(eval_loss, epoch)\n",
    "            # Handle pruning based on the intermediate value\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "        # Return the running loss as the objective value to minimize\n",
    "        return eval_loss      \n",
    "\n",
    "\n",
    "    def get_best_param(self):\n",
    "        # Create an Optuna Study\n",
    "        study = optuna.create_study(direction='minimize', storage='sqlite:///db.sqlite3', study_name=f'{self.station}', load_if_exists=True)\n",
    "\n",
    "        # Run the optimization process\n",
    "        study.optimize(self.objective, n_trials=50)\n",
    "\n",
    "        print(f'{self.station} eval_loss: {study.best_trial.value}')\n",
    "\n",
    "        # Access the best hyperparameters\n",
    "        best_params = study.best_trial.params\n",
    "\n",
    "        self.best_params = best_params\n",
    "\n",
    "        print(self.station,' Best hyperparameters:', best_params)\n",
    "\n",
    "    def train(self):\n",
    "        # Instantiate the final model with the best hyperparameters\n",
    "        final_model = Net(8, self.best_params['hidden_size'], 1, self.best_params['dropout_rate'])\n",
    "\n",
    "        # ... rest of your training code for the final model\n",
    "        criterion = CustomLoss()\n",
    "        optimizer = optim.Adam(final_model.parameters(), lr=self.best_params['learning_rate'])\n",
    "\n",
    "        # train with whole dataset\n",
    "        running_loss = 0.0\n",
    "        for epoch in range(20):\n",
    "            for i, data in enumerate(self.all_data_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = final_model(inputs)\n",
    "                outputs = outputs.squeeze()\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()/128\n",
    "            print(f'epoch: {epoch+1}, loss: {running_loss/self.all_data_loader.__len__()}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "        final_model.eval()\n",
    "        # save model\n",
    "        torch.save(final_model.state_dict(), f'models/model_{self.station}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get data loader for 500101001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 12:54:37,720] Using an existing study with name '500101001' instead of creating a new one.\n",
      "[W 2023-12-02 12:54:37,775] Trial 50 failed with parameters: {'hidden_size': 1543, 'learning_rate': 0.0057020209914659765, 'dropout_rate': 0.33804936906957256} because of the following error: NameError(\"name 'Net' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yl/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/l8/cns8rbyx5y17d2vn6gf6qkk80000gn/T/ipykernel_66548/1530220195.py\", line 44, in objective\n",
      "    model = Net(input_size, hidden_size, output_size, dropout_rate)\n",
      "            ^^^\n",
      "NameError: name 'Net' is not defined\n",
      "[W 2023-12-02 12:54:37,776] Trial 50 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yl/HTML/final/model.ipynb Cell 15\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m station \u001b[39m=\u001b[39m station_model(station_id)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m station\u001b[39m.\u001b[39mget_data_loader()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m station\u001b[39m.\u001b[39;49mget_best_param()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m station\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstation_id\u001b[39m}\u001b[39;00m\u001b[39m done\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/yl/HTML/final/model.ipynb Cell 15\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, storage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msqlite:///db.sqlite3\u001b[39m\u001b[39m'\u001b[39m, study_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstation\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, load_if_exists\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m# Run the optimization process\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstation\u001b[39m}\u001b[39;00m\u001b[39m eval_loss: \u001b[39m\u001b[39m{\u001b[39;00mstudy\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# Access the best hyperparameters\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/html-qsiNAWFM-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/yl/HTML/final/model.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m dropout_rate \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.7\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Instantiate the model with sampled hyperparameters\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m model \u001b[39m=\u001b[39m Net(input_size, hidden_size, output_size, dropout_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Define the loss function and optimizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X16sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m criterion \u001b[39m=\u001b[39m CustomLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Net' is not defined"
     ]
    }
   ],
   "source": [
    "available_station = np.loadtxt('html.2023.final.data/sno_test_set.txt', dtype='str')\n",
    "first35_station = available_station[:35]\n",
    "\n",
    "for station_id in first35_station:\n",
    "    station = station_model(station_id)\n",
    "    station.get_data_loader()\n",
    "    station.get_best_param()\n",
    "    station.train()\n",
    "    print(f'{station_id} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yl/HTML/final/model.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load model from /models\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# build the gradient boosting regression model with PyTorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mNet\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_size, hidden_size, output_size, dropout_rate):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yl/HTML/final/model.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39msuper\u001b[39m(Net, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# load model from /models\n",
    "# build the gradient boosting regression model with PyTorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, outputs, labels):\n",
    "        # Define your custom loss function here\n",
    "        # This is a simple example, replace it with your own function\n",
    "        custom_loss = 3*(torch.abs(labels - outputs))*(torch.abs(labels - 1/3) + torch.abs(labels -2/3))\n",
    "        return custom_loss\n",
    "\n",
    "\n",
    "# ...\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    input_size = 8\n",
    "    hidden_size = trial.suggest_int('hidden_size', 3, 10000, log=True)  # Single hidden size for all layers\n",
    "    output_size = 1\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e1, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.7)\n",
    "\n",
    "    # Instantiate the model with sampled hyperparameters\n",
    "    model = Net(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = CustomLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(100):\n",
    "        training_loss = 0.0\n",
    "        eval_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.reshape(-1)\n",
    "            loss = criterion(outputs, labels).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        # Iterate over the DataLoader for test data\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                outputs = model(inputs).reshape(-1)\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                eval_loss += loss\n",
    "\n",
    "        # Optuna logs the running loss for each epoch\n",
    "        trial.report(eval_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Return the running loss as the objective value to minimize\n",
    "    return eval_loss\n",
    "model = Net(8, 4096, 1)\n",
    "model.load_state_dict(torch.load('models/model_500101001.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "html-qsiNAWFM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
